{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greenmetro/FarmHelper/blob/master/PMDA_%EB%AC%B8%EC%84%9C_%EA%B8%B0%EB%B0%98_Gemma_%EB%AA%A8%EB%8D%B8_%ED%95%99%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# Step 1: 환경 설정 및 라이브러리 설치\n",
        "# ==============================================================================\n",
        "# GPU 가속을 위해 필요한 라이브러리들을 설치합니다.\n",
        "# 'pdfplumber'는 표/이미지 추출을 위해, 'transformers'는 LLaVA 모델을 위해, 'Pillow'는 이미지 처리를 위해 필요합니다.\n",
        "!pip uninstall -y Pillow torchvision\n",
        "!pip install transformers accelerate peft bitsandbytes pypdf python-dotenv datasets pdfplumber markdownify Pillow torchvision trl --no-cache-dir\n",
        "\n",
        "# 필요한 라이브러리를 불러옵니다.\n",
        "import requests\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "import pdfplumber\n",
        "import markdownify\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "from transformers import AutoProcessor, LlavaForConditionalGeneration, TrainingArguments\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "from trl import SFTTrainer\n",
        "from PIL import Image\n",
        "import logging\n",
        "\n",
        "# 로깅 설정\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# ==============================================================================\n",
        "# Step 2: PMDA 문서 다운로드 및 텍스트/표/이미지 추출\n",
        "# ==============================================================================\n",
        "def download_and_parse_documents(urls, save_dir=\"pmda_docs\", img_dir=\"pmda_images\"):\n",
        "    \"\"\"\n",
        "    PMDA 문서 URL 리스트에서 PDF 파일을 다운로드하고, 텍스트, 표, 이미지를 추출합니다.\n",
        "\n",
        "    Args:\n",
        "        urls (list): PDF 파일 URL 리스트.\n",
        "        save_dir (str): PDF 파일을 저장할 디렉토리.\n",
        "        img_dir (str): 추출된 이미지를 저장할 디렉토리.\n",
        "\n",
        "    Returns:\n",
        "        dict: 파일 경로, 추출된 텍스트, 그리고 이미지 파일 경로를 담은 딕셔너리.\n",
        "    \"\"\"\n",
        "    Path(save_dir).mkdir(exist_ok=True)\n",
        "    Path(img_dir).mkdir(exist_ok=True)\n",
        "    extracted_data = {}\n",
        "\n",
        "    for url in urls:\n",
        "        file_name = url.split('/')[-1]\n",
        "        file_path = os.path.join(save_dir, file_name)\n",
        "\n",
        "        try:\n",
        "            logger.info(f\"Downloading {file_name}...\")\n",
        "            response = requests.get(url, timeout=30)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            with open(file_path, 'wb') as f:\n",
        "                f.write(response.content)\n",
        "\n",
        "            logger.info(f\"Extracting text, tables, and images from {file_name}...\")\n",
        "            document_text = \"\"\n",
        "            extracted_images = []\n",
        "\n",
        "            with pdfplumber.open(file_path) as pdf:\n",
        "                for i, page in enumerate(pdf.pages):\n",
        "                    # 페이지 내의 모든 텍스트 추출\n",
        "                    document_text += page.extract_text() or \"\"\n",
        "\n",
        "                    # 페이지 내의 모든 표 추출 및 마크다운으로 변환\n",
        "                    tables = page.extract_tables()\n",
        "                    for table_data in tables:\n",
        "                        if not table_data: continue\n",
        "                        header = table_data[0]\n",
        "                        rows = table_data[1:]\n",
        "\n",
        "                        table_string = \"\\n| \" + \" | \".join(header) + \" |\\n\"\n",
        "                        table_string += \"| \" + \" | \".join(['---'] * len(header)) + \" |\\n\"\n",
        "                        for row in rows:\n",
        "                            table_string += \"| \" + \" | \".join([str(cell) if cell is not None else '' for cell in row]) + \" |\\n\"\n",
        "\n",
        "                        document_text += \"\\n\" + table_string + \"\\n\"\n",
        "\n",
        "                    # 페이지 내의 이미지 추출 및 저장\n",
        "                    images = page.images\n",
        "                    for img_data in images:\n",
        "                        img_name = f\"{file_name}_page_{i+1}_{img_data['x']:g}_{img_data['y']:g}.png\"\n",
        "                        img_path = os.path.join(img_dir, img_name)\n",
        "\n",
        "                        if 'stream' in img_data:\n",
        "                            img = Image.open(img_data['stream'])\n",
        "                            img.save(img_path)\n",
        "                            extracted_images.append(img_path)\n",
        "\n",
        "            # 불필요한 공백과 개행 제거\n",
        "            clean_text = ' '.join(document_text.split())\n",
        "            extracted_data[file_name] = {\n",
        "                \"text\": clean_text,\n",
        "                \"images\": extracted_images\n",
        "            }\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            logger.error(f\"Failed to download {url}: {e}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to extract data from {file_name}: {e}\")\n",
        "\n",
        "    return extracted_data\n",
        "\n",
        "# PMDA 문서의 예시 URL 리스트\n",
        "pmda_urls = [\n",
        "    \"https://www.pmda.go.jp/drugs/2024/P20240219001/300242000_30200AMX00502_B100_1.pdf\"\n",
        "]\n",
        "downloaded_docs = download_and_parse_documents(pmda_urls)\n",
        "\n",
        "# ==============================================================================\n",
        "# Step 3: 학습용 데이터셋 생성 및 변환\n",
        "# ==============================================================================\n",
        "def create_multimodal_instruction_dataset(extracted_data):\n",
        "    \"\"\"\n",
        "    추출된 텍스트, 표, 이미지를 Gemma 모델 학습에 적합한 JSONL 형식으로 변환합니다.\n",
        "    \"\"\"\n",
        "    dataset_list = []\n",
        "\n",
        "    for filename, data in extracted_data.items():\n",
        "        document_part = data[\"text\"][:2000] # 앞부분 2000자 사용\n",
        "        image_path = data[\"images\"][0] if data[\"images\"] else None # 첫 번째 이미지 사용\n",
        "\n",
        "        if image_path:\n",
        "            # 멀티모달 학습용 프롬프트 구성\n",
        "            instruction = f\"문서와 이미지를 분석하고 다음 질문에 답해줘: 이 보고서의 핵심 내용과 이미지에 나타난 그래프의 의미는 무엇인가요?\"\n",
        "            output = \"이 문서는 의약품의 임상 데이터를 다루며, 첨부된 그래프는 약물 투여량에 따른 환자의 반응률을 보여줍니다. 그래프는 용량 증가에 따라 반응률이 높아지는 경향을 나타냅니다.\"\n",
        "\n",
        "            dataset_list.append({\n",
        "                \"instruction\": instruction,\n",
        "                \"image_path\": image_path,\n",
        "                \"output\": output\n",
        "            })\n",
        "        else:\n",
        "            # 이미지가 없는 경우 텍스트만 사용\n",
        "            instruction = f\"다음 문서를 요약해줘: {document_part}\"\n",
        "            output = \"이 문서는 의약품 신청서에 대한 기술적 평가 보고서입니다.\"\n",
        "\n",
        "            dataset_list.append({\n",
        "                \"instruction\": instruction,\n",
        "                \"output\": output\n",
        "            })\n",
        "\n",
        "    return Dataset.from_list(dataset_list)\n",
        "\n",
        "train_dataset = create_multimodal_instruction_dataset(downloaded_docs)\n",
        "logger.info(\"Generated training dataset:\")\n",
        "logger.info(train_dataset)\n",
        "logger.info(\"First example in the dataset:\")\n",
        "if len(train_dataset) > 0:\n",
        "    logger.info(train_dataset[0])\n",
        "else:\n",
        "    logger.warning(\"Training dataset is empty. Cannot display the first example.\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# Step 4: LLaVA 모델 추가 학습 (Fine-tuning)\n",
        "# ==============================================================================\n",
        "def load_and_train_llava(dataset):\n",
        "    \"\"\"\n",
        "    LLaVA 모델을 로드하고 LoRA 기법을 사용하여 추가 학습을 진행합니다.\n",
        "    \"\"\"\n",
        "    if len(dataset) == 0:\n",
        "        logger.error(\"Cannot train the model with an empty dataset.\")\n",
        "        return\n",
        "\n",
        "    model_name = \"llava-hf/llava-1.5-7b-hf\"\n",
        "    new_model_name = \"llava-1.5-7b-finetuned-pmda\"\n",
        "\n",
        "    # 모델을 4-bit 양자화로 로드하기 위한 설정\n",
        "    bnb_config = BitsandBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "    )\n",
        "\n",
        "    # 프로세서와 모델 로드 (LLaVA는 별도의 프로세서가 필요)\n",
        "    logger.info(\"Loading processor and model...\")\n",
        "    processor = AutoProcessor.from_pretrained(model_name)\n",
        "    model = LlavaForConditionalGeneration.from_pretrained(\n",
        "        model_name,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map=\"auto\"\n",
        "    )\n",
        "\n",
        "    # LoRA 설정 (PEFT)\n",
        "    peft_config = LoraConfig(\n",
        "        r=16,\n",
        "        lora_alpha=32,\n",
        "        lora_dropout=0.05,\n",
        "        bias=\"none\",\n",
        "        task_type=\"CAUSAL_LM\",\n",
        "    )\n",
        "    model = get_peft_model(model, peft_config)\n",
        "    model.print_trainable_parameters()\n",
        "\n",
        "    # 데이터셋 전처리 함수\n",
        "    def preprocess_multimodal(examples):\n",
        "        image_path = examples['image_path']\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        prompt = examples['instruction']\n",
        "\n",
        "        # LLaVA용 프롬프트 형식\n",
        "        full_prompt = f\"USER: <image>\\n{prompt} ASSISTANT: {examples['output']}\"\n",
        "\n",
        "        # 모델 입력에 맞게 토큰화 및 이미지 전처리\n",
        "        inputs = processor(text=full_prompt, images=image, return_tensors=\"pt\")\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": inputs.input_ids[0],\n",
        "            \"attention_mask\": inputs.attention_mask[0],\n",
        "            \"pixel_values\": inputs.pixel_values[0],\n",
        "            \"labels\": inputs.input_ids[0] # self-supervised learning\n",
        "        }\n",
        "\n",
        "    # 훈련 매개변수 설정\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./results\",\n",
        "        per_device_train_batch_size=4,\n",
        "        gradient_accumulation_steps=4,\n",
        "        learning_rate=2e-4,\n",
        "        logging_steps=10,\n",
        "        max_steps=100,\n",
        "        fp16=True,\n",
        "        optim=\"paged_adamw_8bit\",\n",
        "        save_strategy=\"epoch\"\n",
        "    )\n",
        "\n",
        "    # SFTTrainer를 사용한 모델 학습\n",
        "    # LLaVA는 데이터셋을 수동으로 전처리해야 하므로, SFTTrainer를 직접 사용하기보다\n",
        "    # `transformers.Trainer`를 사용하는 것이 더 적합합니다.\n",
        "    # 여기서는 SFTTrainer의 데이터 로딩 기능을 활용하고, 실제 학습은 Trainer를 흉내냅니다.\n",
        "    logger.warning(\"SFTTrainer is used for simplicity, but a custom Trainer might be better for complex multimodal tasks.\")\n",
        "\n",
        "    trainer = SFTTrainer(\n",
        "        model=model,\n",
        "        train_dataset=dataset,\n",
        "        peft_config=peft_config,\n",
        "        dataset_text_field=\"instruction\",\n",
        "        max_seq_length=2048,\n",
        "        tokenizer=processor.tokenizer,\n",
        "        args=training_args,\n",
        "    )\n",
        "\n",
        "    # LLaVA는 별도의 이미지 전처리 로직이 필요하므로 직접 학습 루프를 구현하거나\n",
        "    # `transformers.Trainer`를 사용하는 것이 더 정확합니다.\n",
        "    # 아래 code는 LLaVA의 작동 방식을 설명하기 위한 단순화된 예시입니다.\n",
        "    logger.info(\"Starting model training...\")\n",
        "    trainer.train()\n",
        "\n",
        "    # 학습된 모델 저장\n",
        "    trainer.save_model(new_model_name)\n",
        "    logger.info(f\"Model saved to ./{new_model_name}\")\n",
        "\n",
        "# 메인 실행\n",
        "load_and_train_llava(train_dataset)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: pillow 12.0.0\n",
            "Uninstalling pillow-12.0.0:\n",
            "  Successfully uninstalled pillow-12.0.0\n",
            "Found existing installation: torchvision 0.24.0\n",
            "Uninstalling torchvision-0.24.0:\n",
            "  Successfully uninstalled torchvision-0.24.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.17.1)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.48.2)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.1.3)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.12/dist-packages (0.11.7)\n",
            "Requirement already satisfied: markdownify in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "Collecting Pillow\n",
            "  Downloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.24.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: trl in /usr/local/lib/python3.12/dist-packages (0.25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: pdfminer.six==20250506 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (20250506)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (5.0.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20250506->pdfplumber) (3.4.4)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20250506->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.9 in /usr/local/lib/python3.12/dist-packages (from markdownify) (4.13.5)\n",
            "Requirement already satisfied: six<2,>=1.15 in /usr/local/lib/python3.12/dist-packages (from markdownify) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5,>=4.9->markdownify) (2.8)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.0.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.23)\n",
            "Downloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.24.0-cp312-cp312-manylinux_2_28_x86_64.whl (8.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m162.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Pillow, torchvision\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gradio 5.49.1 requires pillow<12.0,>=8.0, but you have pillow 12.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-12.0.0 torchvision-0.24.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:__main__:Failed to extract data from 300242000_30200AMX00502_B100_1.pdf: 'x'\n",
            "WARNING:__main__:Training dataset is empty. Cannot display the first example.\n",
            "ERROR:__main__:Cannot train the model with an empty dataset.\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hviMNRSjpzn0",
        "outputId": "1d178d6a-83f8-4f8e-fa26-a6b0a768615b"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}